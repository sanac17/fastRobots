<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Lab 10 - ECE 5160: Fast Robots</title>
  <link rel="stylesheet" href="style.css">
  <script type="text/javascript" async src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script type="text/javascript" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>
  <header class="header">
    <div class="nav-container">
      <a href="lab9.html" class="home-link">Lab 10: Localization (Simulation)</a>
      <nav class="nav-menu">
        <a href="index.html" class="home-link">Home</a>
      </nav>
    </div>
  </header>

  <section class="task1">
    <h3>Lab Objective/Prelab</h3>
    <p>
      The purpose of this lab is to implement grid localization using a Bayes filter in a simulation environment.
      Before starting work on Lab 10 I went through the lecture slides to familiarize myself better with how the Baye's
      filter works and why it is beneficial for our situation.
      The Baye's filter consists of 2 main steps: a prediction step and an update step. It takes a prior belief
      distribution bel(x_{t-1}), control input u_t, and measurement z_t to calculate the posterior belief distribution
      bel(x_t) about the current state. Line 3 performs the prediction step by calculating the belief before
      incorporating measurements, while line 4 performs the update step by incorporating the measurement likelihood and
      normalizing the distribution with factor η.
    </p>
    <div class="image-container">
      <img src="./images/lab10_bayes.png" alt="ToF readings" class="task-image">
    </div>
  </section>

  <section class="task1">
    <h3>Implementation</h3>
    <p>
      To implement the Baye's filter in the simulation environment, we had to complete the 5 main functions for the
      prediction and update steps.
    </p>
    <h4>Function 1: compute_control()</h4>
    <p>
      The first function to implement was compute_control. This function takes in a current position and a previous
      position and calculates the 3 main odometry control values: rotation_1, translation and rotation_2. I used the
      equations given in the lecture slides to compute these values from the given positions. I also had to make sure to
      normalize the two rotations so that they are within the -180 to 180 deg range.
    </p>
    <div class="image-container">
      <img src="./images/lab10_1_eqs.png" alt="ToF readings" class="task-image">
    </div>
    <div class="image-container">
      <img src="./images/lab10_compute_control.png" alt="ToF readings" class="task-image">
    </div>
    <h4>Function 2: odom_motion_model()</h4>
    <p>
      The second function to implement was odom_motion_model. This function takes in a current position, a previous
      position and a control input u. The output of this function is the probability of each parameter, calculated as
      a Gaussian distributions with mean from u, which is essentially p(x'|x, u). This is just the probability of a
      state given a prior state and action. The function first extracts each of the 3 model
      parameters by calling
      compute_control(). Then we use loc.gaussian() to calculate each individual parameter probability. The output is
      just these 3 probabilities multiplied.
    </p>
    <div class="image-container">
      <img src="./images/lab10_probs.png" alt="ToF readings" class="task-image">
    </div>
    <div class="image-container">
      <img src="./images/lab10_odom_mot.png" alt="ToF readings" class="task-image">
    </div>
    <h4>Function 3: prediction_step()</h4>
    <p>
      The third function to implement was prediction_step(). This function takes in two parameters, the current and
      previous odometry parameters. It performs the predict step of the Baye's filter.
      It first calculates the control variable u using computer_control() then initializes a new belief loc.bel_bar to
      0. It loops over every possible prior cell (x,y,θ) with non-negligible belief, defined by
      a probability threshold (as said in the lab handout I chose a threshold of 0.0001), and every possible new
      cell (x',y',θ'). It then converts both grid indices into real poses via the mapper, and uses the odometry motion
      model to compute the likelihood of moving from (x,y,θ) to (x',y',θ') given u.
      Each of these transition probabilities is weighted by the old belief at (x,y,θ) and
      accumulated into
      bel_bar[x',y',θ']. Finally, I normalized bel_bar so that the total probability sums to one.
    </p>
    <div class="image-container">
      <img src="./images/lab10_pred_step.png" alt="ToF readings" class="task-image">
    </div>
    <p>
      This step of the Baye's filter can be highly computationally inefficient since it loops through all the possible
      cells. Therefore, to reduce computation we set a threshold and only loop through all prior cells with a certain
      threshold of belief.
    </p>
    <h4>Function 4: sensor_model()</h4>
    <p>
      The fourth function to implement was sensor_model(). This function takes in one parameter, the true observations
      of the robot in the map for a particular pose. It then outputs p(z|x), which is the probability of the given
      oberservation given a current state. I used loc.gaussian() to calculate each probability using the observation
      data as the mean.
    </p>
    <div class="image-container">
      <img src="./images/lab10_sensor_model.png" alt="ToF readings" class="task-image">
    </div>
    <h4>Function 5: update_step()</h4>
    <p>
      The last function is the update_step() of the Baye's filter. This function loops over the grid for the
      current states and uses the sensor_model() function to retrieve the probability array. This probability value is
      then used to update loc.bel. Finally, I normalized bel so that the total probability sums to one.
    </p>
    <div class="image-container">
      <img src="./images/lab10_updaye.png" alt="ToF readings" class="task-image">
    </div>
  </section>

  <section class="task1">
    <h3>Running the Simulation</h3>
    <p>
      Lastly, I ran 2 iterations of the simulation using the Baye's Filter. The blue
      line represents the Baye's filter belief, the green line the ground truth and the red line is the odometry
      measurements. Comparing the Baye's filter output to the simple odometry model shows that the Baye's filter
      performs much better.
    </p>
    <h4>Run without Baye's Filter</h4>
    <div class="video-container">
      <iframe width="70%" height="315" src="https://www.youtube.com/embed/bWG9reUjzFo" title="Lab 10 1">
      </iframe>
    </div>
    <h4>Run with Baye's Filter</h4>
    <div class="video-container">
      <iframe width="70%" height="315" src="https://www.youtube.com/embed/GxrZLkHjNfo" title="Lab 9 Stunt">
      </iframe>
    </div>
  </section>

  <section class="task1">
    <h3>Conclusion</h3>
    <p>
      Overall, this lab provided valuable insights into robotic localization techniques and Baye's filter.
    </p>
  </section>

  <section class="task1">
    <h3>References</h3>
    <p>
      I referenced Stephan Wagner and Mikayla's work for Lab 10.
    </p>
  </section>


</body>

</html>